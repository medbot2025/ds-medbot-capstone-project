# Basic RAG pipeline + LLM prompting with streamlit application

**Install streamlit**<br>
One can use the requirements.txt file, I added streamlit there. Or directly using pip, as streamlit is a python package.

<br>

**Groq API key**<br>
You need a groq api key to access the llama model. 
We already used it in the rag project. I just copied the .env file containing this key from the rag project to the main folder here.

<br>

**Run web app**<br>
Go to streamlit folder.<br>
Terminal command:   `streamlit run test_streamlit.py`

<br>
<br>


Now a browser page with the chatbot interface should be visible.          
